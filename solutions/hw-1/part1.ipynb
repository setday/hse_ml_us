{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 1\n",
    "\n",
    "Процедура генерация датасета:\n",
    "Сгенерируйте датасет с 10000 наблюдений и 1000 колонок (сэмплируйте из разных распеределений) и сформируйте из него таргет на сонове 100 колонок + зашумление (общее или небольшое для каждой колонки - постарайтесь сделать так чтобы шум не сильно влиял на корреляции между предикторами и таргетам). Удостоверьтесь, что в датасете существуют колонки, которые не использовались для таргета, но при этом имеют высокую корреляцию с теми, что использовались (покажите это в коде).\n",
    "\n",
    "Реализуйте forward stage wise регрессию стандартным образом и с помощью QR разложения наиболее быстрым образом (засекайте время для всех опробованных вариантов). Замерьте качество и процент колонок, которые были правильно найдены.\n",
    "\n",
    "**Дополнительно**: \n",
    "Попробуйте генерировать данные таким образом, чтобы ошибка постепенно ухудшалась. Подсказка: увеличивайте шум, используйте нелинейные функции и комбинации предикторов. Попробуйте оценить bias и variance для forward stage-wise regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREDICTOR_CNT = 1_000\n",
    "TARGET_PREDICTOR_CNT = 100\n",
    "SAMPLE_CNT = 10_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistributionGenerator:\n",
    "    @staticmethod\n",
    "    def generate_random_exponential(n: int = 10000, scale: float | None = None):\n",
    "        \"\"\"\n",
    "        Generate random exponential distribution\n",
    "        :param n: number of samples\n",
    "        :param scale: scale parameter of the exponential distribution\n",
    "        :return: np.array of random samples\n",
    "        \"\"\"\n",
    "\n",
    "        if scale is None:\n",
    "            scale = np.random.uniform(0.75, 2.0)\n",
    "        return np.random.exponential(scale=scale, size=n)\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_random_uniform(n: int = 10000, low: float | None = None, length: float | None = None):\n",
    "        \"\"\"\n",
    "        Generate random uniform distribution\n",
    "        :param n: number of samples\n",
    "        :param low: lower bound of the uniform distribution\n",
    "        :param length: length of the uniform distribution\n",
    "        :return: np.array of random samples\n",
    "        \"\"\"\n",
    "\n",
    "        # Kekw: using uniform to generate limits to uniform\n",
    "        if low is None:\n",
    "            low = np.random.uniform(-2.0, -1.0)\n",
    "        if length is None:\n",
    "            length = np.random.uniform(1.0, 3.0)\n",
    "        return np.random.uniform(low=low, high=low + length, size=n)\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_random_normal(n: int = 10000, loc: float | None = None, scale: float | None = None):\n",
    "        \"\"\"\n",
    "        Generate random normal distribution\n",
    "        :param n: number of samples\n",
    "        :param loc: mean of the normal distribution\n",
    "        :param scale: standard deviation of the normal distribution\n",
    "        :return: np.array of random samples\n",
    "        \"\"\"\n",
    "\n",
    "        if loc is None:\n",
    "            loc = np.random.uniform(-1.0, 1.0)\n",
    "        if scale is None:\n",
    "            scale = np.random.uniform(0.2, 2.0)\n",
    "        return np.random.normal(loc=loc, scale=scale, size=n)\n",
    "\n",
    "    distribution_fn_list = [\n",
    "        # generate_random_exponential,\n",
    "        # generate_random_uniform,\n",
    "        generate_random_normal,\n",
    "    ]\n",
    "    @staticmethod\n",
    "    def generate_random_distribution(n: int = 10000):\n",
    "        \"\"\"\n",
    "        Generate random distribution\n",
    "        :param n: number of samples\n",
    "        :return: np.array of random samples\n",
    "        \"\"\"\n",
    "\n",
    "        # Choose a random distribution function\n",
    "        distribution_fn = np.random.choice(DistributionGenerator.distribution_fn_list)\n",
    "        return distribution_fn(n)\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_random_noice(n: int = 10000, limit: float = 0.05):\n",
    "        \"\"\"\n",
    "        Generate random noice based on uniform distribution\n",
    "        :param n: number of samples\n",
    "        :param limit: limit of the uniform distribution\n",
    "        :return: np.array of random noice\n",
    "        \"\"\"\n",
    "        return DistributionGenerator.generate_random_uniform(n, -limit, limit * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_predictors_targets_table(noise_level: float = 0.05):\n",
    "    \"\"\"\n",
    "    Create a table with predictors and target\n",
    "    :param noise_level: noise level of the target\n",
    "    :return: pandas data frame with predictors and target, selected predictors and their coefficients (in tuple form)\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate random data\n",
    "    data = {\n",
    "        f\"predictor_{i}\": DistributionGenerator.generate_random_distribution(SAMPLE_CNT)\n",
    "        for i in range(PREDICTOR_CNT)\n",
    "    }\n",
    "\n",
    "    # Choose random predictors for the target and generate coefficients for them\n",
    "    all_predictors = list(data.keys())\n",
    "    selected_predictors = np.random.choice(a=all_predictors, size=TARGET_PREDICTOR_CNT, replace=False)\n",
    "    predictors_koefs = DistributionGenerator.generate_random_uniform(TARGET_PREDICTOR_CNT, 1.0, 2.0)\n",
    "\n",
    "    # Generate target based on the selected predictors\n",
    "    target_predictors_matrix = np.array([\n",
    "        data[predictor] for predictor in selected_predictors\n",
    "    ])\n",
    "    target = predictors_koefs @ target_predictors_matrix\n",
    "\n",
    "    # Add noice to the target\n",
    "    noice = DistributionGenerator.generate_random_noice(SAMPLE_CNT, limit=noise_level)\n",
    "    data[\"target\"] = target + noice\n",
    "\n",
    "    # Create a pandas data frame\n",
    "    data_frame = pd.DataFrame(data)\n",
    "    return data_frame, selected_predictors, predictors_koefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor_0</th>\n",
       "      <th>predictor_1</th>\n",
       "      <th>predictor_2</th>\n",
       "      <th>predictor_3</th>\n",
       "      <th>predictor_4</th>\n",
       "      <th>predictor_5</th>\n",
       "      <th>predictor_6</th>\n",
       "      <th>predictor_7</th>\n",
       "      <th>predictor_8</th>\n",
       "      <th>predictor_9</th>\n",
       "      <th>...</th>\n",
       "      <th>predictor_991</th>\n",
       "      <th>predictor_992</th>\n",
       "      <th>predictor_993</th>\n",
       "      <th>predictor_994</th>\n",
       "      <th>predictor_995</th>\n",
       "      <th>predictor_996</th>\n",
       "      <th>predictor_997</th>\n",
       "      <th>predictor_998</th>\n",
       "      <th>predictor_999</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.002536</td>\n",
       "      <td>-0.283480</td>\n",
       "      <td>4.132056</td>\n",
       "      <td>-2.261734</td>\n",
       "      <td>0.314676</td>\n",
       "      <td>0.328311</td>\n",
       "      <td>-0.531619</td>\n",
       "      <td>-2.600318</td>\n",
       "      <td>-0.533277</td>\n",
       "      <td>-0.683464</td>\n",
       "      <td>...</td>\n",
       "      <td>0.139523</td>\n",
       "      <td>-0.933903</td>\n",
       "      <td>0.774611</td>\n",
       "      <td>0.034123</td>\n",
       "      <td>1.664838</td>\n",
       "      <td>2.849830</td>\n",
       "      <td>0.484816</td>\n",
       "      <td>-0.593783</td>\n",
       "      <td>-0.664478</td>\n",
       "      <td>-4.581401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.760988</td>\n",
       "      <td>-0.050266</td>\n",
       "      <td>-0.456003</td>\n",
       "      <td>2.051371</td>\n",
       "      <td>-0.085769</td>\n",
       "      <td>1.285934</td>\n",
       "      <td>-0.891529</td>\n",
       "      <td>-0.027588</td>\n",
       "      <td>-1.808646</td>\n",
       "      <td>-0.556348</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.672874</td>\n",
       "      <td>-1.365366</td>\n",
       "      <td>-0.203990</td>\n",
       "      <td>-0.306436</td>\n",
       "      <td>0.510762</td>\n",
       "      <td>1.227865</td>\n",
       "      <td>-1.157598</td>\n",
       "      <td>0.044527</td>\n",
       "      <td>-0.356635</td>\n",
       "      <td>-35.077965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.191722</td>\n",
       "      <td>-2.368395</td>\n",
       "      <td>0.455368</td>\n",
       "      <td>-0.321044</td>\n",
       "      <td>0.136216</td>\n",
       "      <td>0.631543</td>\n",
       "      <td>-0.734875</td>\n",
       "      <td>0.072611</td>\n",
       "      <td>-0.390101</td>\n",
       "      <td>-0.319276</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.166634</td>\n",
       "      <td>-0.985328</td>\n",
       "      <td>-0.219437</td>\n",
       "      <td>-1.204799</td>\n",
       "      <td>0.477092</td>\n",
       "      <td>1.518172</td>\n",
       "      <td>-0.011196</td>\n",
       "      <td>-0.044930</td>\n",
       "      <td>-1.041703</td>\n",
       "      <td>14.536550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.718630</td>\n",
       "      <td>0.225351</td>\n",
       "      <td>0.861022</td>\n",
       "      <td>1.313876</td>\n",
       "      <td>0.856478</td>\n",
       "      <td>1.253883</td>\n",
       "      <td>0.289715</td>\n",
       "      <td>-2.198547</td>\n",
       "      <td>0.792668</td>\n",
       "      <td>-0.459761</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.027207</td>\n",
       "      <td>-1.040070</td>\n",
       "      <td>-0.493549</td>\n",
       "      <td>0.408184</td>\n",
       "      <td>1.279196</td>\n",
       "      <td>3.148266</td>\n",
       "      <td>-0.427640</td>\n",
       "      <td>-1.328281</td>\n",
       "      <td>-0.395530</td>\n",
       "      <td>-8.196430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.483937</td>\n",
       "      <td>0.244965</td>\n",
       "      <td>3.575081</td>\n",
       "      <td>2.517484</td>\n",
       "      <td>0.327690</td>\n",
       "      <td>1.010386</td>\n",
       "      <td>-0.072754</td>\n",
       "      <td>2.545971</td>\n",
       "      <td>0.133293</td>\n",
       "      <td>-0.369577</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.061963</td>\n",
       "      <td>-1.003118</td>\n",
       "      <td>0.393518</td>\n",
       "      <td>-1.278046</td>\n",
       "      <td>2.244314</td>\n",
       "      <td>-2.313410</td>\n",
       "      <td>2.890069</td>\n",
       "      <td>-0.318256</td>\n",
       "      <td>-0.820135</td>\n",
       "      <td>-31.811734</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   predictor_0  predictor_1  predictor_2  predictor_3  predictor_4  \\\n",
       "0    -0.002536    -0.283480     4.132056    -2.261734     0.314676   \n",
       "1    -1.760988    -0.050266    -0.456003     2.051371    -0.085769   \n",
       "2     0.191722    -2.368395     0.455368    -0.321044     0.136216   \n",
       "3    -0.718630     0.225351     0.861022     1.313876     0.856478   \n",
       "4     0.483937     0.244965     3.575081     2.517484     0.327690   \n",
       "\n",
       "   predictor_5  predictor_6  predictor_7  predictor_8  predictor_9  ...  \\\n",
       "0     0.328311    -0.531619    -2.600318    -0.533277    -0.683464  ...   \n",
       "1     1.285934    -0.891529    -0.027588    -1.808646    -0.556348  ...   \n",
       "2     0.631543    -0.734875     0.072611    -0.390101    -0.319276  ...   \n",
       "3     1.253883     0.289715    -2.198547     0.792668    -0.459761  ...   \n",
       "4     1.010386    -0.072754     2.545971     0.133293    -0.369577  ...   \n",
       "\n",
       "   predictor_991  predictor_992  predictor_993  predictor_994  predictor_995  \\\n",
       "0       0.139523      -0.933903       0.774611       0.034123       1.664838   \n",
       "1      -1.672874      -1.365366      -0.203990      -0.306436       0.510762   \n",
       "2      -3.166634      -0.985328      -0.219437      -1.204799       0.477092   \n",
       "3      -1.027207      -1.040070      -0.493549       0.408184       1.279196   \n",
       "4      -1.061963      -1.003118       0.393518      -1.278046       2.244314   \n",
       "\n",
       "   predictor_996  predictor_997  predictor_998  predictor_999     target  \n",
       "0       2.849830       0.484816      -0.593783      -0.664478  -4.581401  \n",
       "1       1.227865      -1.157598       0.044527      -0.356635 -35.077965  \n",
       "2       1.518172      -0.011196      -0.044930      -1.041703  14.536550  \n",
       "3       3.148266      -0.427640      -1.328281      -0.395530  -8.196430  \n",
       "4      -2.313410       2.890069      -0.318256      -0.820135 -31.811734  \n",
       "\n",
       "[5 rows x 1001 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame, selected_predictors_true, predictors_koefs_true = create_predictors_targets_table()\n",
    "\n",
    "# Separate predictors and target\n",
    "X = data_frame.loc[:, data_frame.columns != 'target'].to_numpy()\n",
    "y = data_frame[\"target\"].to_numpy()\n",
    "\n",
    "data_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum correlation of selected predictors - target pairs is 0.011405842900809062\n",
      "Maximum correlation of non-selected predictors - target pairs is 0.03311436720677513\n",
      "At least five pairs of non-selected predictors - selected predictors have correlation not less than 0.03752976273208008\n"
     ]
    }
   ],
   "source": [
    "def show_predictors_targets_table_correlation_info(data_frame: pd.DataFrame, selected_predictors_true: np.ndarray):\n",
    "    \"\"\"\n",
    "    Show correlation information between predictors and target\n",
    "    :param data_frame: pandas data frame with predictors and target\n",
    "    :param selected_predictors_true: true selected predictors\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate correlation table for all the predictors and target\n",
    "    correlation_table = data_frame.corr()\n",
    "\n",
    "    # Calculate correlation information for the selected predictors for the target\n",
    "    selected_correlations = correlation_table[\"target\"][selected_predictors_true].to_numpy()\n",
    "    min_selected_correlations = selected_correlations.min()\n",
    "\n",
    "    # Calculate correlation information for the non-selected predictors for the target\n",
    "    non_selected_correlations = correlation_table[\"target\"].drop(labels=selected_predictors_true).drop(labels=\"target\").to_numpy()\n",
    "    max_non_selected_correlations = non_selected_correlations.max()\n",
    "\n",
    "    # Calculate correlation information for the non-selected predictors for the selected predictors\n",
    "    predictors_correlation_table = correlation_table.drop(columns=\"target\").drop(labels=\"target\")\n",
    "    numpy_correlation_table = predictors_correlation_table[selected_predictors_true].drop(labels=selected_predictors_true).to_numpy()\n",
    "    np.fill_diagonal(numpy_correlation_table, 0.0)\n",
    "    five_most_correlated = sorted(numpy_correlation_table.flatten(), reverse=True)[:5 * 2]\n",
    "\n",
    "    print(\"Minimum correlation of selected predictors - target pairs is\", min_selected_correlations)\n",
    "    print(\"Maximum correlation of non-selected predictors - target pairs is\", max_non_selected_correlations)\n",
    "    print(\"At least five pairs of non-selected predictors - selected predictors have correlation not less than\", five_most_correlated[-1])\n",
    "\n",
    "show_predictors_targets_table_correlation_info(data_frame, selected_predictors_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QR decomposition is correct\n"
     ]
    }
   ],
   "source": [
    "def QR_decomposition(X: np.ndarray): # ~3.4s on test (1001, 1003)\n",
    "    \"\"\"\n",
    "    Perform QR decomposition of the matrix X (self-written)\n",
    "    :param X: matrix to decompose\n",
    "    :return: Q and R matrices\n",
    "    \"\"\"\n",
    "\n",
    "    Q = np.zeros_like(X)\n",
    "    R = np.zeros((X.shape[1], X.shape[1]))\n",
    "\n",
    "    for i in range(X.shape[1]):\n",
    "        Q[:, i] = X[:, i]\n",
    "        for j in range(i):\n",
    "            R[j, i] = Q[:, j] @ Q[:, i]\n",
    "            Q[:, i] -= R[j, i] * Q[:, j]\n",
    "        R[i, i] = np.linalg.norm(Q[:, i])\n",
    "        Q[:, i] /= R[i, i]\n",
    "\n",
    "    return Q, R\n",
    "\n",
    "def QR_decomposition_fast(X: np.ndarray): # ~0.2s on test (1001, 1003)\n",
    "    \"\"\"\n",
    "    Perform QR decomposition of the matrix X (numpy)\n",
    "    :param X: matrix to decompose\n",
    "    :return: Q and R matrices\n",
    "    \"\"\"\n",
    "\n",
    "    return np.linalg.qr(X)\n",
    "\n",
    "def test_QR_decomposition():\n",
    "    \"\"\"\n",
    "    Test QR decomposition\n",
    "    \"\"\"\n",
    "\n",
    "    A = np.random.rand(1001, 1003)\n",
    "    Q, R = QR_decomposition(A)\n",
    "    D = Q @ R - A\n",
    "    if max(-D.min(), D.max()) < 1e-6:\n",
    "        print(\"QR decomposition is correct\")\n",
    "    else:\n",
    "        print(\"QR decomposition is incorrect\")\n",
    "\n",
    "test_QR_decomposition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IncrementalForwardStagewiseRegression:\n",
    "    def __init__(self, max_iter: int = 1_500_000, tol: float = 1e-3, step: float = 1e-2, step_decay: float = 0.8):\n",
    "        \"\"\"\n",
    "        Initialize the class\n",
    "        :param max_iter: maximum number of iterations\n",
    "        :param tol: tolerance for the correlation\n",
    "        :param step: step size\n",
    "        :param step_decay: step decay\n",
    "        Default values are specially selected for fit v3\n",
    "        For fit v1 and v2 use max_iter: int = 15_000, tol: float = 1e-3, step: float = 1e-3\n",
    "        \"\"\"\n",
    "\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        self.step = step\n",
    "        self.step_decay = step_decay\n",
    "\n",
    "        self.residual = None\n",
    "        self.beta = None\n",
    "\n",
    "        self.X_mean = None\n",
    "        self.X_std = None\n",
    "\n",
    "        self.y_mean = None\n",
    "        self.y_std = None\n",
    "\n",
    "    def _fit_normalization(self, X: np.ndarray, y: np.ndarray):\n",
    "        \"\"\"\n",
    "        Normalize data\n",
    "        :param X: matrix of predictors\n",
    "        :param y: target vector\n",
    "        \"\"\"\n",
    "\n",
    "        self.X_mean = X.mean(axis=0)\n",
    "        self.X_std = X.std(axis=0)\n",
    "        self.y_mean = y.mean()\n",
    "        self.y_std = y.std()\n",
    "\n",
    "        X = (X - self.X_mean) / self.X_std\n",
    "        y = (y - self.y_mean) / self.y_std\n",
    "\n",
    "        return X, y\n",
    "    \n",
    "    def _normileze_X(self, X: np.ndarray):\n",
    "        return (X - self.X_mean) / self.X_std\n",
    "    \n",
    "    def _unnormalize_y(self, y: np.ndarray):\n",
    "        return y * self.y_std + self.y_mean\n",
    "\n",
    "\n",
    "    def _fit_v1(self, X: np.ndarray, y: np.ndarray):\n",
    "        \"\"\"\n",
    "        Perform incremental forward stagewise regression\n",
    "        :param X: matrix of predictors\n",
    "        :param y: target vector\n",
    "        \"\"\"\n",
    "\n",
    "        # Normalize data\n",
    "        X, y = self._fit_normalization(X, y)\n",
    "\n",
    "        # Initialize variables\n",
    "        residual = y.copy()\n",
    "        self.beta = np.zeros(X.shape[1])\n",
    "\n",
    "        for _ in range(self.max_iter):\n",
    "            # Calculate correlations (slow)\n",
    "            correlations = X.T @ residual\n",
    "            correlations_magnitude = np.abs(correlations)\n",
    "\n",
    "            # Find the best predictor (the one with the highest correlation)\n",
    "            best_predictor = np.argmax(correlations_magnitude)\n",
    "            best_correlation = correlations_magnitude[best_predictor]\n",
    "\n",
    "            # Check if the best correlation is less than the tolerance. So the beta is predicting the target well enough\n",
    "            if best_correlation < self.tol:\n",
    "                print(\"Converged at iteration\", _)\n",
    "                break\n",
    "\n",
    "            # Update beta and residual\n",
    "            self.beta[best_predictor] += self.step * np.sign(correlations[best_predictor])\n",
    "            residual -= self.step * np.sign(correlations[best_predictor]) * X[:, best_predictor]\n",
    "        else:\n",
    "            print(\"Warning: maximum number of iterations reached. Limit was\", self.max_iter)\n",
    "\n",
    "    def _fit_v2(self, X: np.ndarray, y: np.ndarray):\n",
    "        X, y = self._fit_normalization(X, y)\n",
    "\n",
    "        residual = y.copy()\n",
    "        self.beta = np.zeros(X.shape[1])\n",
    "\n",
    "        correlations = X.T @ residual\n",
    "\n",
    "        for _ in range(self.max_iter):\n",
    "            correlations_magnitude = np.abs(correlations)\n",
    "\n",
    "            best_predictor = np.argmax(correlations_magnitude)\n",
    "            best_correlation = correlations_magnitude[best_predictor]\n",
    "\n",
    "            if best_correlation < self.tol:\n",
    "                print(\"Converged at iteration\", _)\n",
    "                break\n",
    "\n",
    "            # Update beta and correlations\n",
    "            self.beta[best_predictor] += self.step * np.sign(correlations[best_predictor])\n",
    "            correlations -= self.step * np.sign(correlations[best_predictor]) * (X.T @ X[:, best_predictor])\n",
    "        else:\n",
    "            print(\"Warning: maximum number of iterations reached. Limit was\", self.max_iter)\n",
    "\n",
    "    def _fit_v3(\n",
    "            self,\n",
    "            X: np.ndarray,\n",
    "            y: np.ndarray,\n",
    "        ):\n",
    "        \"\"\"\n",
    "        Perform incremental forward stagewise regression\n",
    "        (the fastest method without multiplication of the whole matrix)\n",
    "        :param X: matrix of predictors\n",
    "        :param y: target vector\n",
    "        :param max_iter: maximum number of iterations\n",
    "        :param tol: tolerance for the correlation\n",
    "        :param step: step size\n",
    "        :param step_decay: step decay\n",
    "        \"\"\"\n",
    "\n",
    "        X, y = self._fit_normalization(X, y)\n",
    "\n",
    "        step = self.step\n",
    "        self.beta = np.zeros(X.shape[1])\n",
    "\n",
    "        correlations = X.T @ y\n",
    "\n",
    "        XTX = X.T @ X\n",
    "\n",
    "        for _ in range(self.max_iter):\n",
    "            correlations_magnitude = np.abs(correlations)\n",
    "\n",
    "            best_predictor = np.argmax(correlations_magnitude)\n",
    "            best_correlation = correlations_magnitude[best_predictor]\n",
    "\n",
    "            if best_correlation < self.tol:\n",
    "                print(\"Converged at iteration\", _)\n",
    "                break\n",
    "\n",
    "            # Update beta and correlations\n",
    "            self.beta[best_predictor] += step * np.sign(correlations[best_predictor])\n",
    "            correlations -= step * np.sign(correlations[best_predictor]) * XTX[:, best_predictor]\n",
    "\n",
    "            if _ != 0 and _ % 10_000 == 0:\n",
    "                step *= self.step_decay\n",
    "        else:\n",
    "            print(\"Warning: maximum number of iterations reached. Limit was\", self.max_iter)\n",
    "    \n",
    "    def fit(self, X: np.ndarray, y: np.ndarray):\n",
    "        \"\"\"\n",
    "        Fit the model\n",
    "        :param X: matrix of predictors\n",
    "        :param y: target vector\n",
    "        \"\"\"\n",
    "\n",
    "        # self._fit_v1(X, y) # ~19.7s on 15_000 iterations\n",
    "        # self._fit_v2(X, y) # ~19.3s on 15_000 iterations\n",
    "        self._fit_v3(X, y) # ~3.4s on 500_000 iterations (No matrix multiplication in the loop)\n",
    "\n",
    "    def predict(self, X: np.ndarray):\n",
    "        \"\"\"\n",
    "        Predict the target\n",
    "        :param X: matrix of predictors\n",
    "        :return: predicted target\n",
    "        \"\"\"\n",
    "\n",
    "        return self._unnormalize_y(self._normileze_X(X) @ self.beta)\n",
    "    \n",
    "    def compare_coefficients_with_true(self, selected_predictors_true: np.ndarray):\n",
    "        \"\"\"\n",
    "        Compare coefficients with the true ones\n",
    "        :param selected_predictors_true: true selected predictors\n",
    "        \"\"\"\n",
    "\n",
    "        # Find the coefficients that are not zero\n",
    "        coeffs_found = (self.beta > self.tol).sum()\n",
    "        print(f\"Found {coeffs_found} coefficients out of {len(selected_predictors_true)}\")\n",
    "\n",
    "        matched_coeffs = 0\n",
    "\n",
    "        for predictor in selected_predictors_true:\n",
    "            predictor_id = int(predictor.split(\"_\")[-1])\n",
    "            \n",
    "            # There should be a coefficient comparator (self.beta vs predictors_koefs_true),\n",
    "            # but beta was trained on normalized data and predictors_koefs_true used on non-normalized data\n",
    "            # So, we can't compare them =(\n",
    "            if self.beta[predictor_id] > self.tol:\n",
    "                matched_coeffs += 1\n",
    "\n",
    "        print(f\"Matched {matched_coeffs} coefficients out of {len(selected_predictors_true)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged at iteration 490243\n",
      "Found 100 coefficients out of 100\n",
      "Matched 100 coefficients out of 100\n"
     ]
    }
   ],
   "source": [
    "model = IncrementalForwardStagewiseRegression()\n",
    "model.fit(X, y)\n",
    "model.compare_coefficients_with_true(selected_predictors_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: maximum number of iterations reached. Limit was 50000\n",
      "MSE: 0.5299552900259948 | MAE: 0.52743384496775\n"
     ]
    }
   ],
   "source": [
    "def test_on_real_data(model):\n",
    "    \"\"\"\n",
    "    Test the model on real data\n",
    "    :param model: model to test\n",
    "    \"\"\"\n",
    "\n",
    "    data_california = fetch_california_housing()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data_california.data, data_california.target, test_size=0.3, random_state=42)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "    print(f\"MSE: {mse} | MAE: {mae}\")\n",
    "\n",
    "test_on_real_data(IncrementalForwardStagewiseRegression(max_iter=50_000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.5305677824766757 | MAE: 0.5272474538306168\n"
     ]
    }
   ],
   "source": [
    "test_on_real_data(LinearRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
